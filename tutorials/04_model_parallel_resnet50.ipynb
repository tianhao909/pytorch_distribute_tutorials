{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95b4e641",
   "metadata": {},
   "source": [
    "- 参考\n",
    "    - https://pytorch.org/tutorials/intermediate/model_parallel_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6659387c",
   "metadata": {},
   "source": [
    "## outline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1201f0a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T09:51:31.664206Z",
     "start_time": "2023-06-10T09:51:31.653752Z"
    }
   },
   "source": [
    "- 数据并行是切数据（scattering inputs and gathering outputs），模型并行是切模型（shards）；\n",
    "    - 模型并行：单卡放不下一份模型；\n",
    "    - 将一份大模型，不同的层s切分到不同的卡上；\n",
    "- device_map：Huggingface\n",
    "- 模型并行 on ToyModel\n",
    "- 模型并行：on ResNet\n",
    "    - 不需要引入额外的 torch api 支持；"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6007bbf",
   "metadata": {},
   "source": [
    "## huggingface 的支持"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959e0248",
   "metadata": {},
   "source": [
    "### device_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb03b78b",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "\"auto\", \"balanced\", \"balanced_low_0\", \"sequential\"\n",
    "```\n",
    "\n",
    "- `auto`\n",
    "    - GPU(s) > CPU (RAM) > Disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09d5a4c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T10:54:05.602719Z",
     "start_time": "2023-06-10T10:53:50.155859Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, \t cuda:0 \ttorch.float16\n",
      "1, \t cuda:0 \ttorch.int8\n",
      "2, \t cuda:0 \ttorch.int8\n",
      "3, \t cuda:0 \ttorch.int8\n",
      "4, \t cuda:0 \ttorch.int8\n",
      "5, \t cuda:0 \ttorch.int8\n",
      "6, \t cuda:0 \ttorch.int8\n",
      "7, \t cuda:0 \ttorch.int8\n",
      "8, \t cuda:0 \ttorch.float16\n",
      "9, \t cuda:0 \ttorch.float16\n",
      "10, \t cuda:0 \ttorch.int8\n",
      "11, \t cuda:0 \ttorch.int8\n",
      "12, \t cuda:0 \ttorch.int8\n",
      "13, \t cuda:0 \ttorch.int8\n",
      "14, \t cuda:0 \ttorch.int8\n",
      "15, \t cuda:0 \ttorch.int8\n",
      "16, \t cuda:0 \ttorch.int8\n",
      "17, \t cuda:0 \ttorch.float16\n",
      "18, \t cuda:0 \ttorch.float16\n",
      "19, \t cuda:0 \ttorch.int8\n",
      "20, \t cuda:0 \ttorch.int8\n",
      "21, \t cuda:0 \ttorch.int8\n",
      "22, \t cuda:0 \ttorch.int8\n",
      "23, \t cuda:0 \ttorch.int8\n",
      "24, \t cuda:0 \ttorch.int8\n",
      "25, \t cuda:0 \ttorch.int8\n",
      "26, \t cuda:0 \ttorch.float16\n",
      "27, \t cuda:0 \ttorch.float16\n",
      "28, \t cuda:1 \ttorch.int8\n",
      "29, \t cuda:1 \ttorch.int8\n",
      "30, \t cuda:1 \ttorch.int8\n",
      "31, \t cuda:1 \ttorch.int8\n",
      "32, \t cuda:1 \ttorch.int8\n",
      "33, \t cuda:1 \ttorch.int8\n",
      "34, \t cuda:1 \ttorch.int8\n",
      "35, \t cuda:1 \ttorch.float16\n",
      "36, \t cuda:1 \ttorch.float16\n",
      "37, \t cuda:1 \ttorch.int8\n",
      "38, \t cuda:1 \ttorch.int8\n",
      "39, \t cuda:1 \ttorch.int8\n",
      "40, \t cuda:1 \ttorch.int8\n",
      "41, \t cuda:1 \ttorch.int8\n",
      "42, \t cuda:1 \ttorch.int8\n",
      "43, \t cuda:1 \ttorch.int8\n",
      "44, \t cuda:1 \ttorch.float16\n",
      "45, \t cuda:1 \ttorch.float16\n",
      "46, \t cuda:1 \ttorch.int8\n",
      "47, \t cuda:1 \ttorch.int8\n",
      "48, \t cuda:1 \ttorch.int8\n",
      "49, \t cuda:1 \ttorch.int8\n",
      "50, \t cuda:1 \ttorch.int8\n",
      "51, \t cuda:1 \ttorch.int8\n",
      "52, \t cuda:1 \ttorch.int8\n",
      "53, \t cuda:1 \ttorch.float16\n",
      "54, \t cuda:1 \ttorch.float16\n",
      "55, \t cuda:1 \ttorch.int8\n",
      "56, \t cuda:1 \ttorch.int8\n",
      "57, \t cuda:1 \ttorch.int8\n",
      "58, \t cuda:1 \ttorch.int8\n",
      "59, \t cuda:1 \ttorch.int8\n",
      "60, \t cuda:1 \ttorch.int8\n",
      "61, \t cuda:1 \ttorch.int8\n",
      "62, \t cuda:1 \ttorch.float16\n",
      "63, \t cuda:1 \ttorch.float16\n",
      "64, \t cuda:2 \ttorch.int8\n",
      "65, \t cuda:2 \ttorch.int8\n",
      "66, \t cuda:2 \ttorch.int8\n",
      "67, \t cuda:2 \ttorch.int8\n",
      "68, \t cuda:2 \ttorch.int8\n",
      "69, \t cuda:2 \ttorch.int8\n",
      "70, \t cuda:2 \ttorch.int8\n",
      "71, \t cuda:2 \ttorch.float16\n",
      "72, \t cuda:2 \ttorch.float16\n",
      "73, \t cuda:2 \ttorch.int8\n",
      "74, \t cuda:2 \ttorch.int8\n",
      "75, \t cuda:2 \ttorch.int8\n",
      "76, \t cuda:2 \ttorch.int8\n",
      "77, \t cuda:2 \ttorch.int8\n",
      "78, \t cuda:2 \ttorch.int8\n",
      "79, \t cuda:2 \ttorch.int8\n",
      "80, \t cuda:2 \ttorch.float16\n",
      "81, \t cuda:2 \ttorch.float16\n",
      "82, \t cuda:2 \ttorch.int8\n",
      "83, \t cuda:2 \ttorch.int8\n",
      "84, \t cuda:2 \ttorch.int8\n",
      "85, \t cuda:2 \ttorch.int8\n",
      "86, \t cuda:2 \ttorch.int8\n",
      "87, \t cuda:2 \ttorch.int8\n",
      "88, \t cuda:2 \ttorch.int8\n",
      "89, \t cuda:2 \ttorch.float16\n",
      "90, \t cuda:2 \ttorch.float16\n",
      "91, \t cuda:2 \ttorch.int8\n",
      "92, \t cuda:2 \ttorch.int8\n",
      "93, \t cuda:2 \ttorch.int8\n",
      "94, \t cuda:2 \ttorch.int8\n",
      "95, \t cuda:2 \ttorch.int8\n",
      "96, \t cuda:2 \ttorch.int8\n",
      "97, \t cuda:2 \ttorch.int8\n",
      "98, \t cuda:2 \ttorch.float16\n",
      "99, \t cuda:2 \ttorch.float16\n",
      "100, \t cuda:3 \ttorch.int8\n",
      "101, \t cuda:3 \ttorch.int8\n",
      "102, \t cuda:3 \ttorch.int8\n",
      "103, \t cuda:3 \ttorch.int8\n",
      "104, \t cuda:3 \ttorch.int8\n",
      "105, \t cuda:3 \ttorch.int8\n",
      "106, \t cuda:3 \ttorch.int8\n",
      "107, \t cuda:3 \ttorch.float16\n",
      "108, \t cuda:3 \ttorch.float16\n",
      "109, \t cuda:3 \ttorch.int8\n",
      "110, \t cuda:3 \ttorch.int8\n",
      "111, \t cuda:3 \ttorch.int8\n",
      "112, \t cuda:3 \ttorch.int8\n",
      "113, \t cuda:3 \ttorch.int8\n",
      "114, \t cuda:3 \ttorch.int8\n",
      "115, \t cuda:3 \ttorch.int8\n",
      "116, \t cuda:3 \ttorch.float16\n",
      "117, \t cuda:3 \ttorch.float16\n",
      "118, \t cuda:3 \ttorch.int8\n",
      "119, \t cuda:3 \ttorch.int8\n",
      "120, \t cuda:3 \ttorch.int8\n",
      "121, \t cuda:3 \ttorch.int8\n",
      "122, \t cuda:3 \ttorch.int8\n",
      "123, \t cuda:3 \ttorch.int8\n",
      "124, \t cuda:3 \ttorch.int8\n",
      "125, \t cuda:3 \ttorch.float16\n",
      "126, \t cuda:3 \ttorch.float16\n",
      "127, \t cuda:3 \ttorch.int8\n",
      "128, \t cuda:3 \ttorch.int8\n",
      "129, \t cuda:3 \ttorch.int8\n",
      "130, \t cuda:3 \ttorch.int8\n",
      "131, \t cuda:3 \ttorch.int8\n",
      "132, \t cuda:3 \ttorch.int8\n",
      "133, \t cuda:3 \ttorch.int8\n",
      "134, \t cuda:3 \ttorch.float16\n",
      "135, \t cuda:3 \ttorch.float16\n",
      "136, \t cuda:4 \ttorch.int8\n",
      "137, \t cuda:4 \ttorch.int8\n",
      "138, \t cuda:4 \ttorch.int8\n",
      "139, \t cuda:4 \ttorch.int8\n",
      "140, \t cuda:4 \ttorch.int8\n",
      "141, \t cuda:4 \ttorch.int8\n",
      "142, \t cuda:4 \ttorch.int8\n",
      "143, \t cuda:4 \ttorch.float16\n",
      "144, \t cuda:4 \ttorch.float16\n",
      "145, \t cuda:4 \ttorch.int8\n",
      "146, \t cuda:4 \ttorch.int8\n",
      "147, \t cuda:4 \ttorch.int8\n",
      "148, \t cuda:4 \ttorch.int8\n",
      "149, \t cuda:4 \ttorch.int8\n",
      "150, \t cuda:4 \ttorch.int8\n",
      "151, \t cuda:4 \ttorch.int8\n",
      "152, \t cuda:4 \ttorch.float16\n",
      "153, \t cuda:4 \ttorch.float16\n",
      "154, \t cuda:4 \ttorch.int8\n",
      "155, \t cuda:4 \ttorch.int8\n",
      "156, \t cuda:4 \ttorch.int8\n",
      "157, \t cuda:4 \ttorch.int8\n",
      "158, \t cuda:4 \ttorch.int8\n",
      "159, \t cuda:4 \ttorch.int8\n",
      "160, \t cuda:4 \ttorch.int8\n",
      "161, \t cuda:4 \ttorch.float16\n",
      "162, \t cuda:4 \ttorch.float16\n",
      "163, \t cuda:4 \ttorch.int8\n",
      "164, \t cuda:4 \ttorch.int8\n",
      "165, \t cuda:4 \ttorch.int8\n",
      "166, \t cuda:4 \ttorch.int8\n",
      "167, \t cuda:4 \ttorch.int8\n",
      "168, \t cuda:4 \ttorch.int8\n",
      "169, \t cuda:4 \ttorch.int8\n",
      "170, \t cuda:4 \ttorch.float16\n",
      "171, \t cuda:4 \ttorch.float16\n",
      "172, \t cuda:5 \ttorch.int8\n",
      "173, \t cuda:5 \ttorch.int8\n",
      "174, \t cuda:5 \ttorch.int8\n",
      "175, \t cuda:5 \ttorch.int8\n",
      "176, \t cuda:5 \ttorch.int8\n",
      "177, \t cuda:5 \ttorch.int8\n",
      "178, \t cuda:5 \ttorch.int8\n",
      "179, \t cuda:5 \ttorch.float16\n",
      "180, \t cuda:5 \ttorch.float16\n",
      "181, \t cuda:5 \ttorch.int8\n",
      "182, \t cuda:5 \ttorch.int8\n",
      "183, \t cuda:5 \ttorch.int8\n",
      "184, \t cuda:5 \ttorch.int8\n",
      "185, \t cuda:5 \ttorch.int8\n",
      "186, \t cuda:5 \ttorch.int8\n",
      "187, \t cuda:5 \ttorch.int8\n",
      "188, \t cuda:5 \ttorch.float16\n",
      "189, \t cuda:5 \ttorch.float16\n",
      "190, \t cuda:5 \ttorch.int8\n",
      "191, \t cuda:5 \ttorch.int8\n",
      "192, \t cuda:5 \ttorch.int8\n",
      "193, \t cuda:5 \ttorch.int8\n",
      "194, \t cuda:5 \ttorch.int8\n",
      "195, \t cuda:5 \ttorch.int8\n",
      "196, \t cuda:5 \ttorch.int8\n",
      "197, \t cuda:5 \ttorch.float16\n",
      "198, \t cuda:5 \ttorch.float16\n",
      "199, \t cuda:5 \ttorch.int8\n",
      "200, \t cuda:5 \ttorch.int8\n",
      "201, \t cuda:5 \ttorch.int8\n",
      "202, \t cuda:5 \ttorch.int8\n",
      "203, \t cuda:5 \ttorch.int8\n",
      "204, \t cuda:5 \ttorch.int8\n",
      "205, \t cuda:5 \ttorch.int8\n",
      "206, \t cuda:5 \ttorch.float16\n",
      "207, \t cuda:5 \ttorch.float16\n",
      "208, \t cuda:6 \ttorch.int8\n",
      "209, \t cuda:6 \ttorch.int8\n",
      "210, \t cuda:6 \ttorch.int8\n",
      "211, \t cuda:6 \ttorch.int8\n",
      "212, \t cuda:6 \ttorch.int8\n",
      "213, \t cuda:6 \ttorch.int8\n",
      "214, \t cuda:6 \ttorch.int8\n",
      "215, \t cuda:6 \ttorch.float16\n",
      "216, \t cuda:6 \ttorch.float16\n",
      "217, \t cuda:6 \ttorch.int8\n",
      "218, \t cuda:6 \ttorch.int8\n",
      "219, \t cuda:6 \ttorch.int8\n",
      "220, \t cuda:6 \ttorch.int8\n",
      "221, \t cuda:6 \ttorch.int8\n",
      "222, \t cuda:6 \ttorch.int8\n",
      "223, \t cuda:6 \ttorch.int8\n",
      "224, \t cuda:6 \ttorch.float16\n",
      "225, \t cuda:6 \ttorch.float16\n",
      "226, \t cuda:6 \ttorch.int8\n",
      "227, \t cuda:6 \ttorch.int8\n",
      "228, \t cuda:6 \ttorch.int8\n",
      "229, \t cuda:6 \ttorch.int8\n",
      "230, \t cuda:6 \ttorch.int8\n",
      "231, \t cuda:6 \ttorch.int8\n",
      "232, \t cuda:6 \ttorch.int8\n",
      "233, \t cuda:6 \ttorch.float16\n",
      "234, \t cuda:6 \ttorch.float16\n",
      "235, \t cuda:6 \ttorch.int8\n",
      "236, \t cuda:6 \ttorch.int8\n",
      "237, \t cuda:6 \ttorch.int8\n",
      "238, \t cuda:6 \ttorch.int8\n",
      "239, \t cuda:6 \ttorch.int8\n",
      "240, \t cuda:6 \ttorch.int8\n",
      "241, \t cuda:6 \ttorch.int8\n",
      "242, \t cuda:6 \ttorch.float16\n",
      "243, \t cuda:6 \ttorch.float16\n",
      "244, \t cuda:7 \ttorch.int8\n",
      "245, \t cuda:7 \ttorch.int8\n",
      "246, \t cuda:7 \ttorch.int8\n",
      "247, \t cuda:7 \ttorch.int8\n",
      "248, \t cuda:7 \ttorch.int8\n",
      "249, \t cuda:7 \ttorch.int8\n",
      "250, \t cuda:7 \ttorch.int8\n",
      "251, \t cuda:7 \ttorch.float16\n",
      "252, \t cuda:7 \ttorch.float16\n",
      "253, \t cuda:7 \ttorch.int8\n",
      "254, \t cuda:7 \ttorch.int8\n",
      "255, \t cuda:7 \ttorch.int8\n",
      "256, \t cuda:7 \ttorch.int8\n",
      "257, \t cuda:7 \ttorch.int8\n",
      "258, \t cuda:7 \ttorch.int8\n",
      "259, \t cuda:7 \ttorch.int8\n",
      "260, \t cuda:7 \ttorch.float16\n",
      "261, \t cuda:7 \ttorch.float16\n",
      "262, \t cuda:7 \ttorch.int8\n",
      "263, \t cuda:7 \ttorch.int8\n",
      "264, \t cuda:7 \ttorch.int8\n",
      "265, \t cuda:7 \ttorch.int8\n",
      "266, \t cuda:7 \ttorch.int8\n",
      "267, \t cuda:7 \ttorch.int8\n",
      "268, \t cuda:7 \ttorch.int8\n",
      "269, \t cuda:7 \ttorch.float16\n",
      "270, \t cuda:7 \ttorch.float16\n",
      "271, \t cuda:7 \ttorch.int8\n",
      "272, \t cuda:7 \ttorch.int8\n",
      "273, \t cuda:7 \ttorch.int8\n",
      "274, \t cuda:7 \ttorch.int8\n",
      "275, \t cuda:7 \ttorch.int8\n",
      "276, \t cuda:7 \ttorch.int8\n",
      "277, \t cuda:7 \ttorch.int8\n",
      "278, \t cuda:7 \ttorch.float16\n",
      "279, \t cuda:7 \ttorch.float16\n",
      "280, \t cuda:7 \ttorch.int8\n",
      "281, \t cuda:7 \ttorch.int8\n",
      "282, \t cuda:7 \ttorch.int8\n",
      "283, \t cuda:7 \ttorch.int8\n",
      "284, \t cuda:7 \ttorch.int8\n",
      "285, \t cuda:7 \ttorch.int8\n",
      "286, \t cuda:7 \ttorch.int8\n",
      "287, \t cuda:7 \ttorch.float16\n",
      "288, \t cuda:7 \ttorch.float16\n",
      "289, \t cuda:7 \ttorch.float16\n",
      "290, \t cuda:7 \ttorch.float16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import LlamaTokenizer, LlamaForCausalLM, GenerationConfig\n",
    "# /disk2/modelscope/Llama-2-7b-hf\n",
    "# model = LlamaForCausalLM.from_pretrained(\"decapoda-research/llama-7b-hf\",\n",
    "#     load_in_8bit=True,\n",
    "#     device_map=\"auto\",\n",
    "# )\n",
    "model = LlamaForCausalLM.from_pretrained(\"/disk2/modelscope/Llama-2-7b-hf\",\n",
    "    load_in_8bit=True,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "for i, para in enumerate(model.named_parameters()):\n",
    "#     print(f'{i}, {para[0]}\\t {para[1].device} \\t{para[1].dtype}')\n",
    "    print(f'{i}, \\t {para[1].device} \\t{para[1].dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20912f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 导入必要的库：LlamaTokenizer（分词器）、LlamaForCausalLM（模型）、GenerationConfig（生成配置）\n",
    "# from transformers import LlamaTokenizer, LlamaForCausalLM, GenerationConfig\n",
    "\n",
    "# # 注释说明模型路径为 \"/disk2/modelscope/Llama-2-7b-hf\"\n",
    "# # 如果使用远程模型，原语句是：\n",
    "# # model = LlamaForCausalLM.from_pretrained(\"decapoda-research/llama-7b-hf\",\n",
    "# #     load_in_8bit=True,\n",
    "# #     device_map=\"auto\",\n",
    "# # )\n",
    "\n",
    "# # 从本地路径加载 Llama-2-7b 模型，并启用 8-bit 量化（节省显存），自动分配设备（多 GPU 分布式加载）\n",
    "# model = LlamaForCausalLM.from_pretrained(\"/disk2/modelscope/Llama-2-7b-hf\",\n",
    "#     load_in_8bit=True,\n",
    "#     device_map=\"auto\",\n",
    "# )\n",
    "\n",
    "# # 遍历模型的所有参数，打印参数索引、所在设备和数据类型\n",
    "# for i, para in enumerate(model.named_parameters()):\n",
    "#     # 打印格式：参数编号，参数所在的设备（如 cuda:0）和参数的数据类型（如 torch.float16）\n",
    "#     print(f'{i}, \\t {para[1].device} \\t{para[1].dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af9c394",
   "metadata": {},
   "source": [
    "## toy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3eb32a1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T10:55:22.734083Z",
     "start_time": "2023-06-10T10:55:21.401055Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class ToyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ToyModel, self).__init__()\n",
    "        self.net1 = torch.nn.Linear(10000, 10).to('cuda:0')\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.net2 = torch.nn.Linear(10, 5).to('cuda:1')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.net1(x.to('cuda:0')))\n",
    "        return self.net2(x.to('cuda:1'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0b2a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  # 导入 PyTorch 库，用于构建和训练深度学习模型\n",
    "import torch.nn as nn  # 导入神经网络模块\n",
    "import torch.optim as optim  # 导入优化器模块，用于参数更新\n",
    "\n",
    "\n",
    "class ToyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ToyModel, self).__init__()  \n",
    "        # 调用父类 nn.Module 的构造函数。super() 函数的作用是调用父类的方法。\n",
    "        # 这里使用的是 Python 2 风格的 super 写法，在 Python 3 中也可以简写为 super().__init__()\n",
    "        # 在 PyTorch 中，所有自定义模型都应继承 nn.Module 并调用其初始化方法。\n",
    "\n",
    "        self.net1 = torch.nn.Linear(10000, 10).to('cuda:0')  \n",
    "        # 定义一个线性层（全连接层），输入维度为 10000，输出维度为 10，并将其移动到 GPU 0 上\n",
    "\n",
    "        self.relu = torch.nn.ReLU()  \n",
    "        # 定义 ReLU 激活函数层\n",
    "\n",
    "        self.net2 = torch.nn.Linear(10, 5).to('cuda:1')  \n",
    "        # 定义另一个线性层，输入维度为 10，输出维度为 5，并将其移动到 GPU 1 上\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.net1(x.to('cuda:0')))  \n",
    "        # 将输入张量移动到 GPU 0，经过 net1 层处理后，通过 ReLU 激活函数\n",
    "        return self.net2(x.to('cuda:1'))  \n",
    "        # 将中间结果张量移动到 GPU 1，再经过 net2 层处理，返回最终输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c10c8ac6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T10:56:43.186416Z",
     "start_time": "2023-06-10T10:56:42.132385Z"
    }
   },
   "outputs": [],
   "source": [
    "# watch -n 1 nvidia-smi\n",
    "model = ToyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3cd8176a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T10:57:16.966789Z",
     "start_time": "2023-06-10T10:57:16.956120Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.parameter.Parameter"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(list(model.net1.parameters())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5515ad52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T10:57:25.079872Z",
     "start_time": "2023-06-10T10:57:25.070508Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "print(next(model.net1.parameters()).device)\n",
    "print(next(model.net2.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82e1999c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T10:57:39.312339Z",
     "start_time": "2023-06-10T10:57:39.205305Z"
    }
   },
   "outputs": [],
   "source": [
    "model = ToyModel()\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "outputs = model(torch.randn(20, 10000))\n",
    "labels = torch.randn(20, 5).to('cuda:1')\n",
    "loss_fn(outputs, labels).backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4662c7",
   "metadata": {},
   "source": [
    "## split ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb1e1e0",
   "metadata": {},
   "source": [
    "- 简单介绍下 ResNet\n",
    "\n",
    "```\n",
    "model = ResNet(block, layers, **kwargs)\n",
    "\n",
    "# resnet18\n",
    "_resnet(BasicBlock, [2, 2, 2, 2])\n",
    "# resnet34\n",
    "_resnet(BasicBlock, [3, 4, 6, 3])\n",
    "\n",
    "# resnet50\n",
    "_resnet(Bottleneck, [3, 4, 6, 3])\n",
    "# resnet101\n",
    "_resnet(Bottleneck, [3, 4, 23, 3])\n",
    "# resnet152\n",
    "_resnet(Bottleneck, [3, 8, 36, 3])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "593d7bcd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T10:59:32.643357Z",
     "start_time": "2023-06-10T10:59:32.420118Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models.resnet import ResNet, Bottleneck\n",
    "# from torchvision.models.resnet import resnet18, resnet34, resnet50, resnet101, resnet152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b9b2daab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T10:59:37.319217Z",
     "start_time": "2023-06-10T10:59:36.895405Z"
    }
   },
   "outputs": [],
   "source": [
    "# resnet50\n",
    "model = ResNet(Bottleneck, [3, 4, 6, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "05996879",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T10:59:40.283916Z",
     "start_time": "2023-06-10T10:59:40.274490Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conv1 => bn1 => relu => maxpool => layer1-layer4 => avgpool => fc\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b97a8782",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T11:00:49.368357Z",
     "start_time": "2023-06-10T11:00:49.359729Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "44b4d3aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T11:00:50.573133Z",
     "start_time": "2023-06-10T11:00:50.468033Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 64, 64]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 64, 64]             128\n",
      "              ReLU-3           [-1, 64, 64, 64]               0\n",
      "         MaxPool2d-4           [-1, 64, 32, 32]               0\n",
      "            Conv2d-5           [-1, 64, 32, 32]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
      "              ReLU-7           [-1, 64, 32, 32]               0\n",
      "            Conv2d-8           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 32, 32]             128\n",
      "             ReLU-10           [-1, 64, 32, 32]               0\n",
      "           Conv2d-11          [-1, 256, 32, 32]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 32, 32]             512\n",
      "           Conv2d-13          [-1, 256, 32, 32]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 32, 32]             512\n",
      "             ReLU-15          [-1, 256, 32, 32]               0\n",
      "       Bottleneck-16          [-1, 256, 32, 32]               0\n",
      "           Conv2d-17           [-1, 64, 32, 32]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 32, 32]             128\n",
      "             ReLU-19           [-1, 64, 32, 32]               0\n",
      "           Conv2d-20           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 32, 32]             128\n",
      "             ReLU-22           [-1, 64, 32, 32]               0\n",
      "           Conv2d-23          [-1, 256, 32, 32]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 32, 32]             512\n",
      "             ReLU-25          [-1, 256, 32, 32]               0\n",
      "       Bottleneck-26          [-1, 256, 32, 32]               0\n",
      "           Conv2d-27           [-1, 64, 32, 32]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 32, 32]             128\n",
      "             ReLU-29           [-1, 64, 32, 32]               0\n",
      "           Conv2d-30           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 32, 32]             128\n",
      "             ReLU-32           [-1, 64, 32, 32]               0\n",
      "           Conv2d-33          [-1, 256, 32, 32]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 32, 32]             512\n",
      "             ReLU-35          [-1, 256, 32, 32]               0\n",
      "       Bottleneck-36          [-1, 256, 32, 32]               0\n",
      "           Conv2d-37          [-1, 128, 32, 32]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 32, 32]             256\n",
      "             ReLU-39          [-1, 128, 32, 32]               0\n",
      "           Conv2d-40          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 16, 16]             256\n",
      "             ReLU-42          [-1, 128, 16, 16]               0\n",
      "           Conv2d-43          [-1, 512, 16, 16]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 16, 16]           1,024\n",
      "           Conv2d-45          [-1, 512, 16, 16]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-47          [-1, 512, 16, 16]               0\n",
      "       Bottleneck-48          [-1, 512, 16, 16]               0\n",
      "           Conv2d-49          [-1, 128, 16, 16]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 16, 16]             256\n",
      "             ReLU-51          [-1, 128, 16, 16]               0\n",
      "           Conv2d-52          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 16, 16]             256\n",
      "             ReLU-54          [-1, 128, 16, 16]               0\n",
      "           Conv2d-55          [-1, 512, 16, 16]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-57          [-1, 512, 16, 16]               0\n",
      "       Bottleneck-58          [-1, 512, 16, 16]               0\n",
      "           Conv2d-59          [-1, 128, 16, 16]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 16, 16]             256\n",
      "             ReLU-61          [-1, 128, 16, 16]               0\n",
      "           Conv2d-62          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 16, 16]             256\n",
      "             ReLU-64          [-1, 128, 16, 16]               0\n",
      "           Conv2d-65          [-1, 512, 16, 16]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-67          [-1, 512, 16, 16]               0\n",
      "       Bottleneck-68          [-1, 512, 16, 16]               0\n",
      "           Conv2d-69          [-1, 128, 16, 16]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 16, 16]             256\n",
      "             ReLU-71          [-1, 128, 16, 16]               0\n",
      "           Conv2d-72          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 16, 16]             256\n",
      "             ReLU-74          [-1, 128, 16, 16]               0\n",
      "           Conv2d-75          [-1, 512, 16, 16]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-77          [-1, 512, 16, 16]               0\n",
      "       Bottleneck-78          [-1, 512, 16, 16]               0\n",
      "           Conv2d-79          [-1, 256, 16, 16]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 16, 16]             512\n",
      "             ReLU-81          [-1, 256, 16, 16]               0\n",
      "           Conv2d-82            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-83            [-1, 256, 8, 8]             512\n",
      "             ReLU-84            [-1, 256, 8, 8]               0\n",
      "           Conv2d-85           [-1, 1024, 8, 8]         262,144\n",
      "      BatchNorm2d-86           [-1, 1024, 8, 8]           2,048\n",
      "           Conv2d-87           [-1, 1024, 8, 8]         524,288\n",
      "      BatchNorm2d-88           [-1, 1024, 8, 8]           2,048\n",
      "             ReLU-89           [-1, 1024, 8, 8]               0\n",
      "       Bottleneck-90           [-1, 1024, 8, 8]               0\n",
      "           Conv2d-91            [-1, 256, 8, 8]         262,144\n",
      "      BatchNorm2d-92            [-1, 256, 8, 8]             512\n",
      "             ReLU-93            [-1, 256, 8, 8]               0\n",
      "           Conv2d-94            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-95            [-1, 256, 8, 8]             512\n",
      "             ReLU-96            [-1, 256, 8, 8]               0\n",
      "           Conv2d-97           [-1, 1024, 8, 8]         262,144\n",
      "      BatchNorm2d-98           [-1, 1024, 8, 8]           2,048\n",
      "             ReLU-99           [-1, 1024, 8, 8]               0\n",
      "      Bottleneck-100           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-101            [-1, 256, 8, 8]         262,144\n",
      "     BatchNorm2d-102            [-1, 256, 8, 8]             512\n",
      "            ReLU-103            [-1, 256, 8, 8]               0\n",
      "          Conv2d-104            [-1, 256, 8, 8]         589,824\n",
      "     BatchNorm2d-105            [-1, 256, 8, 8]             512\n",
      "            ReLU-106            [-1, 256, 8, 8]               0\n",
      "          Conv2d-107           [-1, 1024, 8, 8]         262,144\n",
      "     BatchNorm2d-108           [-1, 1024, 8, 8]           2,048\n",
      "            ReLU-109           [-1, 1024, 8, 8]               0\n",
      "      Bottleneck-110           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-111            [-1, 256, 8, 8]         262,144\n",
      "     BatchNorm2d-112            [-1, 256, 8, 8]             512\n",
      "            ReLU-113            [-1, 256, 8, 8]               0\n",
      "          Conv2d-114            [-1, 256, 8, 8]         589,824\n",
      "     BatchNorm2d-115            [-1, 256, 8, 8]             512\n",
      "            ReLU-116            [-1, 256, 8, 8]               0\n",
      "          Conv2d-117           [-1, 1024, 8, 8]         262,144\n",
      "     BatchNorm2d-118           [-1, 1024, 8, 8]           2,048\n",
      "            ReLU-119           [-1, 1024, 8, 8]               0\n",
      "      Bottleneck-120           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-121            [-1, 256, 8, 8]         262,144\n",
      "     BatchNorm2d-122            [-1, 256, 8, 8]             512\n",
      "            ReLU-123            [-1, 256, 8, 8]               0\n",
      "          Conv2d-124            [-1, 256, 8, 8]         589,824\n",
      "     BatchNorm2d-125            [-1, 256, 8, 8]             512\n",
      "            ReLU-126            [-1, 256, 8, 8]               0\n",
      "          Conv2d-127           [-1, 1024, 8, 8]         262,144\n",
      "     BatchNorm2d-128           [-1, 1024, 8, 8]           2,048\n",
      "            ReLU-129           [-1, 1024, 8, 8]               0\n",
      "      Bottleneck-130           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-131            [-1, 256, 8, 8]         262,144\n",
      "     BatchNorm2d-132            [-1, 256, 8, 8]             512\n",
      "            ReLU-133            [-1, 256, 8, 8]               0\n",
      "          Conv2d-134            [-1, 256, 8, 8]         589,824\n",
      "     BatchNorm2d-135            [-1, 256, 8, 8]             512\n",
      "            ReLU-136            [-1, 256, 8, 8]               0\n",
      "          Conv2d-137           [-1, 1024, 8, 8]         262,144\n",
      "     BatchNorm2d-138           [-1, 1024, 8, 8]           2,048\n",
      "            ReLU-139           [-1, 1024, 8, 8]               0\n",
      "      Bottleneck-140           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-141            [-1, 512, 8, 8]         524,288\n",
      "     BatchNorm2d-142            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-143            [-1, 512, 8, 8]               0\n",
      "          Conv2d-144            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-146            [-1, 512, 4, 4]               0\n",
      "          Conv2d-147           [-1, 2048, 4, 4]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 4, 4]           4,096\n",
      "          Conv2d-149           [-1, 2048, 4, 4]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 4, 4]           4,096\n",
      "            ReLU-151           [-1, 2048, 4, 4]               0\n",
      "      Bottleneck-152           [-1, 2048, 4, 4]               0\n",
      "          Conv2d-153            [-1, 512, 4, 4]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-155            [-1, 512, 4, 4]               0\n",
      "          Conv2d-156            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-158            [-1, 512, 4, 4]               0\n",
      "          Conv2d-159           [-1, 2048, 4, 4]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 4, 4]           4,096\n",
      "            ReLU-161           [-1, 2048, 4, 4]               0\n",
      "      Bottleneck-162           [-1, 2048, 4, 4]               0\n",
      "          Conv2d-163            [-1, 512, 4, 4]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-165            [-1, 512, 4, 4]               0\n",
      "          Conv2d-166            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-168            [-1, 512, 4, 4]               0\n",
      "          Conv2d-169           [-1, 2048, 4, 4]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 4, 4]           4,096\n",
      "            ReLU-171           [-1, 2048, 4, 4]               0\n",
      "      Bottleneck-172           [-1, 2048, 4, 4]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                 [-1, 1000]       2,049,000\n",
      "================================================================\n",
      "Total params: 25,557,032\n",
      "Trainable params: 25,557,032\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 93.59\n",
      "Params size (MB): 97.49\n",
      "Estimated Total Size (MB): 191.27\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(3, 128, 128), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e6c6fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23d6cf5f",
   "metadata": {},
   "source": [
    "### 自定义模型并行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4f20df8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T11:04:16.626624Z",
     "start_time": "2023-06-10T11:04:16.614728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 12])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.rand((2, 3, 4))\n",
    "print(t.shape)\n",
    "t.view(t.size(0), -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "928d344b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T11:01:31.594634Z",
     "start_time": "2023-06-10T11:01:31.583933Z"
    }
   },
   "outputs": [],
   "source": [
    "class ModelParallelResNet50(ResNet):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super().__init__(Bottleneck, [3, 4, 6, 3], num_classes=num_classes)\n",
    "        # conv1 => bn1 => relu => maxpool => layer1-layer4 => avgpool => fc\n",
    "        self.seq1 = nn.Sequential(\n",
    "            self.conv1,\n",
    "            self.bn1,\n",
    "            self.relu,\n",
    "            self.maxpool,\n",
    "            self.layer1, \n",
    "            self.layer2\n",
    "        ).to('cuda:0')\n",
    "        \n",
    "        self.seq2 = nn.Sequential(\n",
    "            self.layer3, \n",
    "            self.layer4,\n",
    "            self.avgpool,\n",
    "        ).to('cuda:1')\n",
    "        \n",
    "        self.fc.to('cuda:1')\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # model parts（layers） 的一个（卡间）串行，\n",
    "        x = self.seq2(self.seq1(x).to('cuda:1'))\n",
    "        return self.fc(x.view(x.size(0), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77bd822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ModelParallelResNet50(ResNet):\n",
    "#     def __init__(self, num_classes=1000):\n",
    "#         super().__init__(Bottleneck, [3, 4, 6, 3], num_classes=num_classes)  # 调用父类ResNet的构造函数，初始化ResNet50模型结构\n",
    "#         # conv1 => bn1 => relu => maxpool => layer1-layer4 => avgpool => fc\n",
    "#         self.seq1 = nn.Sequential(\n",
    "#             self.conv1,  # 第一层卷积层，负责提取输入图像的低级特征\n",
    "#             self.bn1,   # 批归一化层，用于加速训练并提高模型稳定性\n",
    "#             self.relu,  # 激活函数ReLU，引入非线性\n",
    "#             self.maxpool,  # 最大池化层，降维并提取重要特征\n",
    "#             self.layer1,  # ResNet的第一个残差块组，包含多个Bottleneck模块\n",
    "#             self.layer2   # ResNet的第二个残差块组，进一步提取特征\n",
    "#         ).to('cuda:0')  # 将seq1部分的计算分配到GPU 0上\n",
    "        \n",
    "#         self.seq2 = nn.Sequential(\n",
    "#             self.layer3,  # ResNet的第三个残差块组，提取更深层次的特征\n",
    "#             self.layer4,  # ResNet的第四个残差块组，负责高层次特征提取\n",
    "#             self.avgpool,  # 全局平均池化层，将特征图降维为固定大小\n",
    "#         ).to('cuda:1')  # 将seq2部分的计算分配到GPU 1上\n",
    "        \n",
    "#         self.fc.to('cuda:1')  # 将全连接层（分类器）分配到GPU 1上\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         # model parts（layers） 的一个（卡间）串行，\n",
    "#         x = self.seq2(self.seq1(x).to('cuda:1'))  # 输入x先经过seq1处理，然后通过`.to('cuda:1')`将结果从GPU 0传输到GPU 1，再由seq2处理\n",
    "#         return self.fc(x.view(x.size(0), -1))  # 将特征展平并通过全连接层得到最终分类结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "374455e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T11:04:56.872047Z",
     "start_time": "2023-06-10T11:04:56.864383Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_size(model):\n",
    "    return sum([para.numel() for para in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a5aac0f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T11:05:24.032226Z",
     "start_time": "2023-06-10T11:05:23.624182Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25557032"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_size(ResNet(Bottleneck, [3, 4, 6, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "af29fed8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T11:05:34.089675Z",
     "start_time": "2023-06-10T11:05:33.757310Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25557032"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_size(ModelParallelResNet50())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b081a1",
   "metadata": {},
   "source": [
    "### train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7b7cebe8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T11:07:12.691328Z",
     "start_time": "2023-06-10T11:07:12.684987Z"
    }
   },
   "outputs": [],
   "source": [
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dfc12ad5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T11:07:13.763943Z",
     "start_time": "2023-06-10T11:07:13.751034Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [3],\n",
       "        [1],\n",
       "        [3],\n",
       "        [9]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_indices = torch.LongTensor(5) \\\n",
    "                           .random_(0, num_classes) \\\n",
    "                           .view(5, 1)\n",
    "one_hot_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "52efeeb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T11:07:28.802359Z",
     "start_time": "2023-06-10T11:07:28.788458Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = torch.zeros(5, num_classes) \\\n",
    "                      .scatter_(1, one_hot_indices, 1)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2573c3ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T11:08:49.711577Z",
     "start_time": "2023-06-10T11:08:49.697409Z"
    }
   },
   "outputs": [],
   "source": [
    "num_classes = 1000\n",
    "num_batches = 3\n",
    "batch_size = 120\n",
    "image_w = 128\n",
    "image_h = 128\n",
    "\n",
    "\n",
    "def train(model):\n",
    "    model.train(True)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "    one_hot_indices = torch.LongTensor(batch_size) \\\n",
    "                           .random_(0, num_classes) \\\n",
    "                           .view(batch_size, 1)\n",
    "\n",
    "    for _ in range(num_batches):\n",
    "        # generate random inputs and labels\n",
    "        # (b, c, w, h)\n",
    "        inputs = torch.randn(batch_size, 3, image_w, image_h)\n",
    "        # one hot：(batch_size, num_classes)，行粒度只有一个为1 （one-hot）\n",
    "        # scatter 的三个参数：dim, index, src\n",
    "        labels = torch.zeros(batch_size, num_classes) \\\n",
    "                      .scatter_(1, one_hot_indices, 1)\n",
    "\n",
    "        # run forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs.to('cuda:0'))\n",
    "#         print('outputs', outputs.shape)\n",
    "        # run backward pass\n",
    "        labels = labels.to(outputs.device)\n",
    "        loss_fn(outputs, labels).backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5ce49d87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T11:10:02.945687Z",
     "start_time": "2023-06-10T11:09:52.052107Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plt.switch_backend('Agg')\n",
    "import numpy as np\n",
    "import timeit\n",
    "\n",
    "num_repeat = 10\n",
    "\n",
    "stmt = \"train(model)\"\n",
    "\n",
    "# 模型并行\n",
    "setup = \"model = ModelParallelResNet50()\"\n",
    "mp_run_times = timeit.repeat(\n",
    "    stmt, setup, number=1, repeat=num_repeat, globals=globals())\n",
    "mp_mean, mp_std = np.mean(mp_run_times), np.std(mp_run_times)\n",
    "\n",
    "# 单卡\n",
    "setup = \"import torchvision.models as models;\" + \\\n",
    "        \"model = models.resnet50(num_classes=num_classes).to('cuda:0')\"\n",
    "rn_run_times = timeit.repeat(\n",
    "    stmt, setup, number=1, repeat=num_repeat, globals=globals())\n",
    "rn_mean, rn_std = np.mean(rn_run_times), np.std(rn_run_times)\n",
    "\n",
    "\n",
    "def plot(means, stds, labels, fig_name):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(np.arange(len(means)), means, yerr=stds,\n",
    "           align='center', alpha=0.5, ecolor='red', capsize=10, width=0.6)\n",
    "    ax.set_ylabel('ResNet50 Execution Time (Second)')\n",
    "    ax.set_xticks(np.arange(len(means)))\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.yaxis.grid(True)\n",
    "    plt.tight_layout()\n",
    "#     plt.savefig(fig_name)\n",
    "#     plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbd846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt  # 导入matplotlib库用于绘图\n",
    "# # plt.switch_backend('Agg')  # 切换matplotlib的后端为Agg（非交互模式，适用于无图形界面环境）\n",
    "# import numpy as np  # 导入numpy库用于数值计算\n",
    "# import timeit  # 导入timeit库用于测量代码执行时间\n",
    "\n",
    "# num_repeat = 10  # 定义重复运行次数为10次\n",
    "\n",
    "# stmt = \"train(model)\"  # 定义要测试的语句，这里是调用train函数训练模型\n",
    "\n",
    "# # 模型并行\n",
    "# setup = \"model = ModelParallelResNet50()\"  # 定义模型初始化语句，使用自定义的ModelParallelResNet50类\n",
    "# mp_run_times = timeit.repeat(  # 使用timeit.repeat测量模型并行的执行时间\n",
    "#     stmt, setup, number=1, repeat=num_repeat, globals=globals())  # 测试语句、初始化语句、每个循环运行1次、重复10次、传入全局变量\n",
    "# mp_mean, mp_std = np.mean(mp_run_times), np.std(mp_run_times)  # 计算模型并行的平均时间和标准差\n",
    "\n",
    "# # 单卡\n",
    "# setup = \"import torchvision.models as models;\" + \\  # 定义单卡模型的初始化语句，使用torchvision中的resnet50模型\n",
    "#         \"model = models.resnet50(num_classes=num_classes).to('cuda:0')\"  # 将模型加载到cuda:0设备上\n",
    "# rn_run_times = timeit.repeat(  # 使用timeit.repeat测量单卡模型的执行时间\n",
    "#     stmt, setup, number=1, repeat=num_repeat, globals=globals())  # 测试语句、初始化语句、每个循环运行1次、重复10次、传入全局变量\n",
    "# rn_mean, rn_std = np.mean(rn_run_times), np.std(rn_run_times)  # 计算单卡模型的平均时间和标准差\n",
    "\n",
    "\n",
    "# def plot(means, stds, labels, fig_name):  # 定义绘图函数\n",
    "#     fig, ax = plt.subplots()  # 创建一个画布和子图\n",
    "#     ax.bar(np.arange(len(means)), means, yerr=stds,  # 绘制柱状图，x轴为索引，y轴为平均值，误差条为标准差\n",
    "#            align='center', alpha=0.5, ecolor='red', capsize=10, width=0.6)  # 设置柱状图样式：居中对齐、透明度、误差条颜色、误差条帽大小、柱宽\n",
    "#     ax.set_ylabel('ResNet50 Execution Time (Second)')  # 设置y轴标签为“ResNet50执行时间（秒）”\n",
    "#     ax.set_xticks(np.arange(len(means)))  # 设置x轴刻度为索引\n",
    "#     ax.set_xticklabels(labels)  # 设置x轴刻度标签为传入的标签\n",
    "#     ax.yaxis.grid(True)  # 启用y轴网格线\n",
    "#     plt.tight_layout()  # 自动调整布局以避免重叠\n",
    "# #     plt.savefig(fig_name)  # 保存图像到文件（注释掉）\n",
    "# #     plt.close(fig)  # 关闭画布（注释掉）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f88e513e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T11:10:05.315262Z",
     "start_time": "2023-06-10T11:10:05.145062Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot([mp_mean, rn_mean],\n",
    "     [mp_std, rn_std],\n",
    "     ['Model Parallel', 'Single GPU'],\n",
    "     'mp_vs_rn.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a8815235",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T11:10:32.195022Z",
     "start_time": "2023-06-10T11:10:32.186272Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.19741040412336588), np.float64(0.17997694667428732))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp_mean, rn_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "83edc6f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T11:10:33.784277Z",
     "start_time": "2023-06-10T11:10:33.774970Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.09686494726810044)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mp_mean-rn_mean)/rn_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47550634",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fth-pytorch-gpu-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "169px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
